---
title: "prep-raw-data"
output: html_document
---

# Libraries
```{r message=F, warning=F}
library(rio)
library(here)
library(tidyverse)
library(janitor)
```

# Baseline Data
```{r}
# mturk
dfm_bp <- import(here("data", "baselinep-data.csv")) %>% 
  clean_names() %>% 
  rename(., "id" = "amazon_identifier") %>% 
  mutate(batch = "basep") # import HIT 1

dfm_b1 <- import(here("data", "baseline1-data.csv")) %>% 
  clean_names() %>% 
  rename(., "id" = "amazon_identifier") %>% 
  mutate(batch = "base1") # import HIT 2

# qualtrics
dfq_b <- import(here("data", "qual-baseline-data.csv")) %>% 
  clean_names() # import
```

## MTurk
```{r}
dfm_b <- rbind(dfm_bp, dfm_b1) # bind HIT dfs
```

```{r}
dfm_b_dup <- dfm_b %>% 
  group_by(id) %>% 
  filter(n() > 1) # identify duplicates

dfm_b_app <- dfm_b %>% 
  filter(approval_status == "Approved") # identify approved HITs
```

### Save dfs
```{r}
write.csv(dfm_b_app, "./prepped-data/sep-dfs/b-mturk-app-data.csv")
write.csv(dfm_b_dup, "./prepped-data/sep-dfs/b-mturk-dup-data.csv")
```

## Qualtrics
```{r}
dfq_b1 <- dfq_b %>% 
  filter(id %in% dfm_b_app$id & !id %in% dfm_b_dup$id) # filter out unapproved/
# duplicate observations
```

```{r}
dfq_b1 <- dfq_b1 %>% 
  filter(finished == 1 & consent == 1) # only finished and consenting obs
```

```{r}
bcols <- dfq_b1 %>% 
  colnames()

bcols1 <- rep(NA, length(bcols))

for (i in 1:length(bcols)) {
  
  bcols1[i] = paste(bcols[i], "b", sep = "_")

}

colnames(dfq_b1) <- bcols1 # change col names to indicate baseline

dfq_b1 <- dfq_b1 %>% 
  rename(., id = id_b) # keep id the same for joining
```

### Save dfs
```{r}
write.csv(dfq_b1, "./prepped-data/sep-dfs/b-qual-data.csv")
```

# Sci Cur Data
```{r}
# mturk
dfm_con1 <- import(here("data", "mturk-data-con1.csv")) %>% 
  clean_names() %>% 
  rename(., "id" = "amazon_identifier") %>% 
  mutate(batch = "con1") # import con HIT 1

dfm_con2 <- import(here("data", "mturk-data-con2.csv")) %>% 
  clean_names() %>% 
  rename(., "id" = "amazon_identifier") %>% 
  mutate(batch = "con2") # import con HIT 2

dfm_lib1 <- import(here("data", "mturk-data-lib1.csv"))%>% 
  clean_names() %>% 
  rename(., "id" = "amazon_identifier") %>% 
  mutate(batch = "lib1") # import lib HIT 1

dfm_lib2 <- import(here("data", "mturk-data-lib2.csv"))%>% 
  clean_names() %>% 
  rename(., "id" = "amazon_identifier") %>% 
  mutate(batch = "lib2") # import lib HIT 2

# qualtrics
dfq <- import(here("data", "qual-data.csv")) %>% 
  clean_names() # import
```

## MTurk
```{r}
dfm <- rbind(dfm_con1, dfm_con2, dfm_lib1, dfm_lib2) # bind mturk data into 1 df
```

```{r}
dfm_dup <- dfm %>% 
  group_by(id) %>% 
  filter(n() > 1) # identify duplicates

dfm_dup %>% 
  filter(approval_status == "Approved") %>% 
  select(id)

dup_idall <- c("A3CZNWMYPM3P6E", "A2YC6PEMIRSOAA", "A2BK9RMC0NOIH8", "A2V27A9GZA1NR2",
           "ARFQ8FJRKCUZ6", "A3F9IQB0297J9D", "ATTGD1M94GFR", "A2IQ0QCTQ3KWLT",
           "A2YLK83DQ6PA5Y")

dup_id <- c("A3CZNWMYPM3P6E", "A2YC6PEMIRSOAA", "A2BK9RMC0NOIH8", "A2V27A9GZA1NR2",
           "ARFQ8FJRKCUZ6", "A3F9IQB0297J9D", "ATTGD1M94GFR", "A2YLK83DQ6PA5Y")
# A2IQ0QCTQ3KWLT does have a duplicate but they accessed the survey for 19s
# before exiting so they didn't go beyond the consent page

dfm_nodup <- dfm %>% 
  filter(!id %in% dup_id)
```

```{r}
dfm_app <- dfm_nodup %>% 
  filter(approval_status == "Approved") # identify approved
```

```{r}
dfm_batch <- dfm_app %>% 
  select(id, batch)
```

### Save dfs
```{r}
write.csv(dfm_app, "./prepped-data/sep-dfs/s1-mturk-app-data.csv")
write.csv(dfm_batch, "./prepped-data/sep-dfs/s1-mturk-batch-data.csv")
```

## Qualtrics
```{r echo=F, eval=F}
dfq_dup <- dfq %>% 
  filter(id %in% dup_id)

dfq_dup %>% 
  group_by(id) %>% 
  summarise(n = n()) %>% 
  filter(n > 1) # identify duplicates

# dfq_dup %>% 
#   filter(id == "A2IQ0QCTQ3KWLT" | id == "A2YC6PEMIRSOAA" | id == "A3F9IQB0297J9D") %>% 
#   select(start_date, end_date, id, finished, duration_in_seconds, consent1,
#          bad_resp, cheat)
# 
# dfq %>% 
#   filter(!id %in% dup_id & id %in% dfm_app$id)
```

```{r}
dfq1 <- dfq %>% 
  filter(!id %in% dup_id & finished == 1 & cheat == 3 & bad_resp == 1 &
           consent1 == 1 & id %in% dfm_app$id) # exlude duplicates and 
# Ss who reported cheating or responding randomly/while distracted, select
# only finished and approved HITs

# nEED TO CREATE A MISSINGNESS VARIABLE TO FILTER W -- MORE THAN 5%****
```

```{r}
cols <- dfq1 %>% 
  colnames()

cols1 <- rep(NA, length(cols))

for (i in 1:length(cols)) {
  
  cols1[i] = paste(cols[i], "sc", sep = "_")

} # mark study 1 cols

colnames(dfq1) <- cols1

dfq1 <- dfq1 %>% 
  rename(., id = id_sc)
```

```{r}
dfq2 <- inner_join(dfq1, dfm_batch, by = "id", all = F)

# dfq2 %>% 
#   select(batch)
```

```{r echo=F, eval=F}
# dfq2 %>% 
#   filter(id %in% dfq1$id)
# 
# dfq2_unqiue <- dfq2$id %>% 
#   unique()
# 
# dfq2$id %>% 
#   unique() %>% 
#   length()
# 
# dfq1_unique <- dfq1$id %>% 
#   unique()
# 
# dfq1_unique %>% 
#   length()
# 
# dfq2 %>% 
#   filter(id %in% dfq1_unqiue)
# 
# dfq1 %>% 
#   filter(id == "A2IQ0QCTQ3KWLT")
# 
# dfm_batch$id %>% 
#   unique() %>% 
#   length()
```

### Save dfs
```{r}
write.csv(dfq2, "./prepped-data/sep-dfs/s1-qual-data.csv")
write.csv(dfq_b1, "./prepped-data/sep-dfs/b-qual-data.csv")
```

# Join (df1)
```{r}
df1 <- inner_join(dfq2, dfq_b1, by = "id", all = F) # join baseline and study 1 q data
```

## Save dfs
```{r}
write.csv(df1, "./prepped-data/joined-data.csv")
```

